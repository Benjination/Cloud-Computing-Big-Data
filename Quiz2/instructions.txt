# Complete Flask Web Application Setup Guide for Data Analysis

## OVERVIEW
This is a comprehensive guide to recreate a sophisticated Flask web application for data analysis. This application was originally built for earthquake data analysis but is designed to be adaptable to any dataset with numeric, temporal, and geographic fields.

## APPLICATION ARCHITECTURE

### Core Components:
1. Flask Web Application (app.py) - Main backend with REST API endpoints
2. HTML Templates - Professional web interface with interactive features
3. Database Integration - Azure SQL Database (or SQLite for local development)
4. CSV Upload System - Automated data import functionality
5. Analysis Engine - Multiple data analysis and visualization features

### Key Features Implemented:
- Search & Filter System: Numeric ranges, location-based searches, temporal filtering
- Analysis Tools: Day/night patterns, weekend analysis, clustering detection
- Interactive UI: Pagination, loading indicators, responsive design
- Error Handling: Robust database connection and data validation
- Scalable Architecture: Ready for different datasets with minimal changes

## REQUIRED FILE STRUCTURE

Create this exact folder structure:

```
project-folder/
‚îú‚îÄ‚îÄ app.py                          # Main Flask application
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îú‚îÄ‚îÄ upload_csv_to_sql.py            # CSV upload utility
‚îú‚îÄ‚îÄ .env                           # Environment variables (create this)
‚îú‚îÄ‚îÄ .env.example                   # Environment template
‚îú‚îÄ‚îÄ instructions.txt               # This file
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îú‚îÄ‚îÄ index.html                 # Main dashboard
‚îÇ   ‚îî‚îÄ‚îÄ search.html                # Search and analysis page
‚îî‚îÄ‚îÄ static/ (optional)             # CSS/JS files if needed
```

## STEP-BY-STEP SETUP PROCESS

### 1. Python Environment Setup

```bash
# Create virtual environment
python -m venv venv

# Activate environment
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install flask pyodbc gunicorn python-dotenv
```

### 2. Create requirements.txt
```
flask
pyodbc
gunicorn
python-dotenv
```

### 3. Environment Configuration

Create .env file:
```
AZURE_SQL_SERVER=your-server.database.windows.net
AZURE_SQL_DATABASE=your-database-name
AZURE_SQL_USERNAME=your-username
AZURE_SQL_PASSWORD=your-password
```

Create .env.example template:
```
AZURE_SQL_SERVER=your-server.database.windows.net
AZURE_SQL_DATABASE=your-database-name
AZURE_SQL_USERNAME=your-username
AZURE_SQL_PASSWORD=your-password
```

## DATABASE SCHEMA PATTERN

### Core Table Structure (adapt field names for your dataset):
```sql
CREATE TABLE your_data_table (
    id INT IDENTITY(1,1) PRIMARY KEY,
    
    -- Temporal fields
    time DATETIME2,
    date_field DATE,
    
    -- Numeric analysis fields
    primary_value FLOAT,           -- Main searchable numeric field
    secondary_value FLOAT,         -- Secondary numeric field
    
    -- Geographic fields (if applicable)
    latitude FLOAT,
    longitude FLOAT,
    
    -- Text/categorical fields
    location_name NVARCHAR(500),
    category NVARCHAR(100),
    description NVARCHAR(1000),
    
    -- Metadata
    source NVARCHAR(50),
    updated DATETIME2,
    created_at DATETIME2 DEFAULT GETDATE()
);

-- Performance indexes
CREATE INDEX IX_primary_value ON your_data_table(primary_value);
CREATE INDEX IX_location ON your_data_table(latitude, longitude);
CREATE INDEX IX_time ON your_data_table(time);
CREATE INDEX IX_category ON your_data_table(category);
```

## CORE FLASK APPLICATION TEMPLATE

### Essential app.py Structure:

```python
"""
Data Analysis Web Application
[Your Name]
[Course Information]
[Assignment Details]

Features:
- Search data by numeric ranges
- Geographic location filtering
- Temporal pattern analysis
- Interactive web interface
- CSV data import functionality
"""

from flask import Flask, jsonify, render_template, request
import os
import math
import pyodbc
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()
app = Flask(__name__)

# Database configuration
SQL_SERVER = os.getenv('AZURE_SQL_SERVER')
SQL_DATABASE = os.getenv('AZURE_SQL_DATABASE')
SQL_USERNAME = os.getenv('AZURE_SQL_USERNAME')
SQL_PASSWORD = os.getenv('AZURE_SQL_PASSWORD')

def get_db_connection():
    """Create database connection"""
    connection_string = f"""
    DRIVER={{ODBC Driver 17 for SQL Server}};
    SERVER={SQL_SERVER};
    DATABASE={SQL_DATABASE};
    UID={SQL_USERNAME};
    PWD={SQL_PASSWORD};
    Encrypt=yes;
    TrustServerCertificate=no;
    Connection Timeout=30;
    CommandTimeout=30;
    """
    try:
        conn = pyodbc.connect(connection_string)
        return conn
    except Exception as e:
        print(f"Database connection error: {e}")
        raise

def init_database():
    """Create tables and indexes if they don't exist"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Create your table here
        create_table_sql = """
        IF NOT EXISTS (SELECT * FROM sysobjects WHERE name='your_table_name' AND xtype='U')
        CREATE TABLE your_table_name (
            id INT IDENTITY(1,1) PRIMARY KEY,
            time DATETIME2,
            primary_value FLOAT,
            latitude FLOAT,
            longitude FLOAT,
            description NVARCHAR(500),
            created_at DATETIME2 DEFAULT GETDATE()
        );
        """
        
        cursor.execute(create_table_sql)
        
        # Create indexes for better performance
        indexes_sql = [
            "IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_primary_value') CREATE INDEX IX_primary_value ON your_table_name(primary_value);",
            "IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_location') CREATE INDEX IX_location ON your_table_name(latitude, longitude);",
            "IF NOT EXISTS (SELECT * FROM sys.indexes WHERE name = 'IX_time') CREATE INDEX IX_time ON your_table_name(time);"
        ]
        
        for index_sql in indexes_sql:
            cursor.execute(index_sql)
        
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        print(f"Database initialization error: {e}")
        return False

# Core routes that need to be implemented:
@app.route('/')
def index():
    """Main dashboard"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Test connection and get record count
        cursor.execute("SELECT COUNT(*) FROM your_table_name")
        record_count = cursor.fetchone()[0]
        
        # Get table list
        cursor.execute("SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE'")
        tables = [row[0] for row in cursor.fetchall()]
        
        conn.close()
        
        # For the template variables it expects
        blobs = "N/A - Using SQL Database"
        
    except Exception as e:
        record_count = f"Error: {e}"
        tables = f"Error: {e}"
        blobs = f"Error: {e}"
    
    return render_template('index.html', 
                         earthquake_count=record_count,  # Change to your count variable
                         tables=tables,
                         blobs=blobs)

@app.route('/search')
def search():
    """Search interface"""
    return render_template('search.html')

@app.route('/search/greater-than/<float:threshold>')
def search_greater_than(threshold):
    """Search by numeric threshold"""
    try:
        threshold = float(threshold)
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        sql = f"SELECT time, latitude, longitude, primary_value, description FROM your_table_name WHERE primary_value > {threshold} ORDER BY primary_value DESC"
        cursor.execute(sql)
        
        results = []
        for row in cursor.fetchall():
            # Handle time field formatting
            time_str = row[0] if row[0] else ''
            if hasattr(time_str, 'isoformat'):
                time_formatted = time_str.isoformat()
            else:
                time_formatted = str(time_str) if time_str else ''
            
            results.append({
                'time': time_formatted,
                'latitude': float(row[1]) if row[1] is not None else 0.0,
                'longitude': float(row[2]) if row[2] is not None else 0.0,
                'magnitude': float(row[3]) if row[3] is not None else 0.0,  # Change field name as needed
                'place': row[4] if row[4] else '',
            })
        
        conn.close()
        
        return jsonify({
            'status': 'success',
            'query': f'Primary Value > {threshold}',
            'count': len(results),
            'earthquakes': results  # Change key name as needed
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/search/range/<float:min_val>/<float:max_val>')
def search_range(min_val, max_val):
    """Search within numeric range"""
    try:
        min_val = float(min_val)
        max_val = float(max_val)
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        sql = f"SELECT time, latitude, longitude, primary_value, description FROM your_table_name WHERE primary_value BETWEEN {min_val} AND {max_val} ORDER BY primary_value DESC"
        cursor.execute(sql)
        
        results = []
        for row in cursor.fetchall():
            # Handle time field formatting
            time_str = row[0] if row[0] else ''
            if hasattr(time_str, 'isoformat'):
                time_formatted = time_str.isoformat()
            else:
                time_formatted = str(time_str) if time_str else ''
            
            results.append({
                'time': time_formatted,
                'latitude': float(row[1]) if row[1] is not None else 0.0,
                'longitude': float(row[2]) if row[2] is not None else 0.0,
                'magnitude': float(row[3]) if row[3] is not None else 0.0,  # Change field name as needed
                'place': row[4] if row[4] else '',
            })
        
        conn.close()
        
        return jsonify({
            'status': 'success',
            'query': f'Primary Value {min_val} - {max_val}',
            'count': len(results),
            'earthquakes': results  # Change key name as needed
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

def haversine_distance(lat1, lon1, lat2, lon2):
    """Calculate the great circle distance between two points on earth in kilometers"""
    try:
        lat1 = float(lat1) if lat1 is not None else None
        lon1 = float(lon1) if lon1 is not None else None
        lat2 = float(lat2) if lat2 is not None else None
        lon2 = float(lon2) if lon2 is not None else None
    except (ValueError, TypeError):
        return float('inf')
    
    if lat1 is None or lon1 is None or lat2 is None or lon2 is None:
        return float('inf')
    
    R = 6371  # Radius of earth in kilometers
    
    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    
    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
    c = 2 * math.asin(math.sqrt(a))
    
    return R * c

@app.route('/search/near-location/<float:latitude>/<float:longitude>/<float:radius_km>')
def search_near_location(latitude, longitude, radius_km):
    """Find records within specified radius of a location"""
    try:
        latitude = float(latitude)
        longitude = float(longitude)
        radius_km = float(radius_km)
        
        # Validate coordinate ranges
        if not (-90 <= latitude <= 90):
            return jsonify({'status': 'error', 'message': f'Invalid latitude: {latitude}. Must be between -90 and 90.'}), 400
        
        if not (-180 <= longitude <= 180):
            return jsonify({'status': 'error', 'message': f'Invalid longitude: {longitude}. Must be between -180 and 180.'}), 400
            
        if not (1 <= radius_km <= 20000):
            return jsonify({'status': 'error', 'message': f'Invalid radius: {radius_km}km. Must be between 1 and 20000 km.'}), 400
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        sql = "SELECT time, latitude, longitude, primary_value, description FROM your_table_name WHERE latitude IS NOT NULL AND longitude IS NOT NULL"
        cursor.execute(sql)
        
        results = []
        for row in cursor.fetchall():
            eq_lat = float(row[1]) if row[1] is not None else 0.0
            eq_lon = float(row[2]) if row[2] is not None else 0.0
            eq_value = float(row[3]) if row[3] is not None else 0.0
            
            distance = haversine_distance(latitude, longitude, eq_lat, eq_lon)
            
            if distance <= radius_km:
                time_str = row[0] if row[0] else ''
                if hasattr(time_str, 'isoformat'):
                    time_formatted = time_str.isoformat()
                else:
                    time_formatted = str(time_str) if time_str else ''
                
                results.append({
                    'time': time_formatted,
                    'latitude': eq_lat,
                    'longitude': eq_lon,
                    'magnitude': eq_value,  # Change field name as needed
                    'place': row[4] if row[4] else '',
                    'distance_km': round(distance, 2)
                })
        
        results.sort(key=lambda x: x['distance_km'])
        conn.close()
        
        return jsonify({
            'status': 'success',
            'query': f'Within {radius_km}km of ({latitude}, {longitude})',
            'count': len(results),
            'earthquakes': results  # Change key name as needed
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/analysis/time-patterns')
def analyze_time_patterns():
    """Analyze temporal patterns"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        sql = "SELECT time FROM your_table_name WHERE time IS NOT NULL"
        cursor.execute(sql)
        
        day_count = 0
        night_count = 0
        
        for row in cursor.fetchall():
            time_dt = row[0]
            if time_dt:
                try:
                    if isinstance(time_dt, str):
                        dt = datetime.fromisoformat(time_dt.replace('Z', '+00:00'))
                        hour = dt.hour
                    else:
                        hour = time_dt.hour
                    
                    # Consider 6 PM to 6 AM as "night"
                    if hour >= 18 or hour < 6:
                        night_count += 1
                    else:
                        day_count += 1
                except (ValueError, AttributeError):
                    continue
        
        conn.close()
        
        total = day_count + night_count
        night_percentage = (night_count / total * 100) if total > 0 else 0
        day_percentage = (day_count / total * 100) if total > 0 else 0
        
        return jsonify({
            'status': 'success',
            'count': total,
            'analysis': 'Time Pattern Analysis - Day vs Night',
            'day_count': day_count,
            'night_count': night_count,
            'total_large_quakes': total,  # Change name as needed
            'day_percentage': round(day_percentage, 1),
            'night_percentage': round(night_percentage, 1),
            'conclusion': f'{night_percentage:.1f}% of records occur at night (6 PM - 6 AM)'
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

if __name__ == '__main__':
    init_database()
    app.run(debug=True)
```

## FRONTEND TEMPLATE PATTERNS

### Dashboard Template (index.html) Key Components:
```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Analysis Dashboard</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 10px;
            text-align: center;
            margin-bottom: 30px;
        }
        .status-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        .status-card {
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .action-buttons {
            display: flex;
            gap: 15px;
            justify-content: center;
            flex-wrap: wrap;
        }
        .btn {
            background-color: #007bff;
            color: white;
            padding: 15px 30px;
            text-decoration: none;
            border-radius: 5px;
            display: inline-block;
            transition: background-color 0.3s;
        }
        .btn:hover {
            background-color: #0056b3;
            text-decoration: none;
            color: white;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üìä Data Analysis Dashboard</h1>
        <p>Your Data Analysis Platform</p>
    </div>

    <div class="status-grid">
        <div class="status-card">
            <h3>üìã Database Status</h3>
            <p><strong>Records:</strong> {{ earthquake_count }}</p>
            <p><strong>Tables:</strong> 
            {% if tables is string %}
                {{ tables }}
            {% else %}
                {{ tables|length }} tables found
            {% endif %}
            </p>
        </div>
        
        <div class="status-card">
            <h3>üîß System Status</h3>
            <p><strong>Database:</strong> Connected</p>
            <p><strong>Storage:</strong> {{ blobs }}</p>
        </div>
    </div>

    <div class="action-buttons">
        <a href="/search" class="btn">üîç Search & Analysis</a>
    </div>

    <div style="margin-top: 30px; padding: 20px; background: white; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
        <h3>üìã Features</h3>
        <ul>
            <li>‚úÖ SQL Database implementation</li>
            <li>‚úÖ CSV data import functionality</li>
            <li>‚úÖ Search by numeric ranges</li>
            <li>‚úÖ Geographic location filtering</li>
            <li>‚úÖ Temporal pattern analysis</li>
            <li>‚úÖ Interactive web interface</li>
            <li>‚úÖ Comprehensive analysis tools</li>
        </ul>
    </div>
</body>
</html>
```

### Search Template (search.html) Key Features:
```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Search & Analysis</title>
    <style>
        /* Professional styling with responsive design */
        body {
            font-family: Arial, sans-serif;
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .search-section {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
        }
        .search-form input, .search-form button {
            padding: 8px 12px;
            margin: 5px;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .search-form button {
            background-color: #007bff;
            color: white;
            cursor: pointer;
            border: none;
        }
        .quick-links {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        .quick-link {
            background-color: #007bff;
            color: white;
            padding: 15px;
            text-align: center;
            border-radius: 5px;
            text-decoration: none;
            display: block;
        }
        .results {
            margin-top: 20px;
            padding: 15px;
            background-color: #e9ecef;
            border-radius: 5px;
            max-height: 400px;
            overflow-y: auto;
        }
        .pagination {
            margin: 20px 0;
            text-align: center;
        }
        .pagination button {
            background-color: #007bff;
            color: white;
            border: none;
            padding: 8px 12px;
            margin: 0 2px;
            border-radius: 4px;
            cursor: pointer;
        }
        .loading {
            display: none;
            text-align: center;
            padding: 40px;
        }
        .loading-spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #007bff;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 20px;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="{{ url_for('index') }}" style="color: #007bff; text-decoration: none;">‚Üê Back to Dashboard</a>
        
        <h1>üîç Data Search & Analysis</h1>
        
        <!-- Quick Analysis Links -->
        <div class="search-section">
            <h2>üìä Quick Analysis</h2>
            <div class="quick-links">
                <a href="#" onclick="quickSearch('/search/greater-than/5.0', 'high values')" class="quick-link">
                    High Value Records
                </a>
                <a href="#" onclick="quickSearch('/analysis/time-patterns', 'time analysis')" class="quick-link">
                    Time Pattern Analysis
                </a>
            </div>
        </div>
        
        <!-- Numeric Search -->
        <div class="search-section">
            <h2>üî¢ Search by Value</h2>
            <div class="search-form">
                <label>Greater than value:</label>
                <input type="number" id="valueGreater" step="0.1" min="0" max="100" value="5.0">
                <button onclick="searchValueGreater()">Search</button>
            </div>
            
            <div class="search-form">
                <label>Value range:</label>
                <input type="number" id="valueMin" step="0.1" min="0" max="100" value="2.0" placeholder="Min">
                <input type="number" id="valueMax" step="0.1" min="0" max="100" value="5.0" placeholder="Max">
                <button onclick="searchValueRange()">Search Range</button>
            </div>
        </div>
        
        <!-- Location Search -->
        <div class="search-section">
            <h2>üìç Search Near Location</h2>
            <div class="search-form">
                <label>Latitude:</label>
                <input type="number" id="searchLat" step="0.0001" placeholder="e.g., 35.6762" value="35.6762" min="-90" max="90">
                <label>Longitude:</label>
                <input type="number" id="searchLng" step="0.0001" placeholder="e.g., 139.6503" value="139.6503" min="-180" max="180">
                <label>Radius (km):</label>
                <input type="number" id="searchRadius" min="1" max="1000" value="100">
                <button onclick="searchNearLocation()">Search</button>
            </div>
        </div>
        
        <!-- Loading Area -->
        <div id="loading" class="loading">
            <div class="loading-spinner"></div>
            <div>Searching data...</div>
        </div>
        
        <!-- Results Area -->
        <div id="results" class="results" style="display: none;">
            <h3>Results</h3>
            <div class="results-per-page">
                <label>Results per page:</label>
                <select id="resultsPerPage" onchange="changeResultsPerPage()">
                    <option value="10">10</option>
                    <option value="20" selected>20</option>
                    <option value="50">50</option>
                    <option value="100">100</option>
                </select>
            </div>
            <div id="resultsContent"></div>
            <div id="pagination" class="pagination" style="display: none;">
                <button id="prevPage" onclick="goToPage(currentPage - 1)">Previous</button>
                <span>Page <span id="currentPageSpan">1</span> of <span id="totalPagesSpan">1</span></span>
                <button id="nextPage" onclick="goToPage(currentPage + 1)">Next</button>
            </div>
        </div>
    </div>

    <script>
        // Pagination variables
        let allResults = [];
        let currentPage = 1;
        let resultsPerPage = 20;
        let totalPages = 1;
        let currentResultsType = null;

        function showLoading() {
            document.getElementById('loading').style.display = 'block';
            document.getElementById('results').style.display = 'none';
        }

        function hideLoading() {
            document.getElementById('loading').style.display = 'none';
        }

        function searchValueGreater() {
            const value = document.getElementById('valueGreater').value;
            showLoading();
            
            fetch(`/search/greater-than/${value}`)
                .then(response => response.json())
                .then(data => {
                    hideLoading();
                    displayResults(data);
                })
                .catch(error => {
                    hideLoading();
                    displayResults({status: 'error', message: 'Search failed: ' + error.message});
                });
        }

        function searchValueRange() {
            const minVal = document.getElementById('valueMin').value;
            const maxVal = document.getElementById('valueMax').value;
            showLoading();
            
            fetch(`/search/range/${minVal}/${maxVal}`)
                .then(response => response.json())
                .then(data => {
                    hideLoading();
                    displayResults(data);
                })
                .catch(error => {
                    hideLoading();
                    displayResults({status: 'error', message: 'Search failed: ' + error.message});
                });
        }

        function searchNearLocation() {
            const lat = document.getElementById('searchLat').value;
            const lng = document.getElementById('searchLng').value;
            const radius = document.getElementById('searchRadius').value;
            showLoading();
            
            fetch(`/search/near-location/${lat}/${lng}/${radius}`)
                .then(response => response.json())
                .then(data => {
                    hideLoading();
                    displayResults(data);
                })
                .catch(error => {
                    hideLoading();
                    displayResults({status: 'error', message: 'Search failed: ' + error.message});
                });
        }

        function quickSearch(url, searchType) {
            showLoading();
            
            fetch(url)
                .then(response => response.json())
                .then(data => {
                    hideLoading();
                    displayResults(data);
                })
                .catch(error => {
                    hideLoading();
                    displayResults({status: 'error', message: 'Search failed: ' + error.message});
                });
        }

        function displayResults(data) {
            const resultsDiv = document.getElementById('results');
            const contentDiv = document.getElementById('resultsContent');
            const paginationDiv = document.getElementById('pagination');
            
            if (data.status === 'success') {
                allResults = data;
                currentPage = 1;
                
                if (data.analysis) {
                    currentResultsType = 'analysis';
                    paginationDiv.style.display = 'none';
                } else if (data.earthquakes) {  // Change this key name for your data
                    currentResultsType = 'earthquakes';
                    totalPages = Math.ceil(data.earthquakes.length / resultsPerPage);
                    paginationDiv.style.display = totalPages > 1 ? 'block' : 'none';
                }
                
                renderCurrentPage();
            } else {
                contentDiv.innerHTML = `<strong>‚ùå Error:</strong> ${data.message}`;
                paginationDiv.style.display = 'none';
            }
            
            resultsDiv.style.display = 'block';
            resultsDiv.scrollIntoView({ behavior: 'smooth' });
        }

        function renderCurrentPage() {
            const contentDiv = document.getElementById('resultsContent');
            const data = allResults;
            
            let html = `<strong>${data.query || 'Search Results'}</strong><br>`;
            html += `Found ${data.count} records<br><br>`;
            
            if (currentResultsType === 'analysis') {
                html += `<strong>Analysis:</strong> ${data.analysis}<br>`;
                
                // Handle different analysis types
                if (data.day_count !== undefined && data.night_count !== undefined) {
                    html += `Total: ${data.total_large_quakes}<br>`;
                    html += `Day: ${data.day_count} (${data.day_percentage}%)<br>`;
                    html += `Night: ${data.night_count} (${data.night_percentage}%)<br>`;
                }
                
                html += `<br><strong>Conclusion:</strong> ${data.conclusion}<br>`;
            } else if (currentResultsType === 'earthquakes' && data.earthquakes) {  // Change key name
                const startIndex = (currentPage - 1) * resultsPerPage;
                const endIndex = Math.min(startIndex + resultsPerPage, data.earthquakes.length);
                const pageResults = data.earthquakes.slice(startIndex, endIndex);
                
                html += `<p><em>Showing ${startIndex + 1}-${endIndex} of ${data.earthquakes.length} results</em></p>`;
                
                html += '<table border="1" style="width:100%; border-collapse: collapse;">';
                html += '<tr><th>Time</th><th>Location</th><th>Value</th><th>Description</th>';
                if (data.earthquakes[0] && data.earthquakes[0].distance_km !== undefined) {
                    html += '<th>Distance (km)</th>';
                }
                html += '</tr>';
                
                pageResults.forEach(record => {
                    html += `<tr>
                        <td>${record.time.split('T')[0]}</td>
                        <td>${record.latitude.toFixed(3)}, ${record.longitude.toFixed(3)}</td>
                        <td><strong>${record.magnitude}</strong></td>
                        <td>${record.place}</td>`;
                    if (record.distance_km !== undefined) {
                        html += `<td>${record.distance_km}</td>`;
                    }
                    html += '</tr>';
                });
                html += '</table>';
                
                updatePaginationControls();
            }
            
            contentDiv.innerHTML = html;
        }

        function updatePaginationControls() {
            const prevBtn = document.getElementById('prevPage');
            const nextBtn = document.getElementById('nextPage');
            const currentPageSpan = document.getElementById('currentPageSpan');
            const totalPagesSpan = document.getElementById('totalPagesSpan');
            
            prevBtn.disabled = currentPage <= 1;
            nextBtn.disabled = currentPage >= totalPages;
            currentPageSpan.textContent = currentPage;
            totalPagesSpan.textContent = totalPages;
        }

        function goToPage(page) {
            if (page >= 1 && page <= totalPages) {
                currentPage = page;
                renderCurrentPage();
            }
        }

        function changeResultsPerPage() {
            const select = document.getElementById('resultsPerPage');
            resultsPerPage = parseInt(select.value);
            
            if (currentResultsType === 'earthquakes' && allResults.earthquakes) {
                totalPages = Math.ceil(allResults.earthquakes.length / resultsPerPage);
                currentPage = 1;
                renderCurrentPage();
                
                const paginationDiv = document.getElementById('pagination');
                paginationDiv.style.display = totalPages > 1 ? 'block' : 'none';
            }
        }
    </script>
</body>
</html>
```

## CSV UPLOAD SYSTEM

### Upload Script Template (upload_csv_to_sql.py):
```python
"""
CSV to Database Uploader
[Your Name]
[Course Information]

This script reads data from a CSV file and uploads it to the database.
"""

import csv
import pyodbc
from datetime import datetime
import os

# Database connection details
SERVER = 'your-server.database.windows.net'
DATABASE = 'your-database'
USERNAME = 'your-username'
PASSWORD = input("Enter your SQL password: ")

# Create connection string
connection_string = f"""
Driver={{ODBC Driver 17 for SQL Server}};
Server=tcp:{SERVER},1433;
Database={DATABASE};
Uid={USERNAME};
Pwd={PASSWORD};
Encrypt=yes;
TrustServerCertificate=no;
Connection Timeout=30;
"""

def create_table(cursor):
    """Create the data table if it doesn't exist"""
    create_table_sql = """
    IF NOT EXISTS (SELECT * FROM sysobjects WHERE name='your_table_name' AND xtype='U')
    CREATE TABLE your_table_name (
        id INT IDENTITY(1,1) PRIMARY KEY,
        time DATETIME2,
        primary_value FLOAT,
        latitude FLOAT,
        longitude FLOAT,
        description NVARCHAR(500),
        category NVARCHAR(100),
        updated DATETIME2
    );
    """
    
    cursor.execute(create_table_sql)
    print("Table created or already exists")

def parse_datetime(date_string):
    """Parse datetime string from CSV"""
    if not date_string or date_string.strip() == '':
        return None
    
    try:
        # Try different datetime formats
        formats = [
            '%Y-%m-%dT%H:%M:%S.%fZ',
            '%Y-%m-%d %H:%M:%S',
            '%Y-%m-%d',
            '%m/%d/%Y %H:%M:%S',
            '%m/%d/%Y'
        ]
        
        for fmt in formats:
            try:
                return datetime.strptime(date_string.strip(), fmt)
            except ValueError:
                continue
        
        # If none work, return None
        return None
    except Exception as e:
        print(f"Error parsing date '{date_string}': {e}")
        return None

def safe_float(value):
    """Safely convert string to float"""
    try:
        return float(value) if value and value.strip() else None
    except (ValueError, TypeError):
        return None

def upload_csv_data(csv_file_path):
    """Upload CSV data to database"""
    try:
        # Connect to database
        conn = pyodbc.connect(connection_string)
        cursor = conn.cursor()
        
        # Create table if it doesn't exist
        create_table(cursor)
        
        # Prepare insert statement
        insert_sql = """
        INSERT INTO your_table_name (time, primary_value, latitude, longitude, description, category, updated)
        VALUES (?, ?, ?, ?, ?, ?, ?)
        """
        
        # Read and process CSV file
        with open(csv_file_path, 'r', newline='', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            
            batch_size = 1000
            records_processed = 0
            batch_records = []
            
            for row in reader:
                try:
                    # Map CSV columns to database fields
                    time_val = parse_datetime(row.get('time', ''))  # Change column name
                    primary_value = safe_float(row.get('magnitude', ''))  # Change column name
                    latitude = safe_float(row.get('latitude', ''))
                    longitude = safe_float(row.get('longitude', ''))
                    description = row.get('place', '')[:500] if row.get('place') else None  # Change column name
                    category = row.get('type', '')[:100] if row.get('type') else None  # Change column name
                    updated = parse_datetime(row.get('updated', ''))  # Change column name
                    
                    # Add to batch
                    batch_records.append((
                        time_val, primary_value, latitude, longitude, 
                        description, category, updated
                    ))
                    
                    # Process batch when it reaches batch_size
                    if len(batch_records) >= batch_size:
                        cursor.executemany(insert_sql, batch_records)
                        conn.commit()
                        records_processed += len(batch_records)
                        print(f"Processed {records_processed} records...")
                        batch_records = []
                
                except Exception as e:
                    print(f"Error processing row {records_processed + 1}: {e}")
                    continue
            
            # Process remaining records
            if batch_records:
                cursor.executemany(insert_sql, batch_records)
                conn.commit()
                records_processed += len(batch_records)
            
            print(f"Successfully uploaded {records_processed} records to database")
        
        conn.close()
        
    except Exception as e:
        print(f"Error uploading data: {e}")

if __name__ == "__main__":
    csv_file = input("Enter the path to your CSV file: ")
    if os.path.exists(csv_file):
        upload_csv_data(csv_file)
    else:
        print("File not found!")
```

## CUSTOMIZATION GUIDE FOR NEW DATASETS

### What You Need to Modify:

1. **Database Schema** (in `init_database()` function):
   - Change table name from `your_table_name` to your actual table name
   - Modify field names and types to match your data
   - Update indexes for your search patterns

2. **CSV Field Mapping** (in `upload_csv_to_sql.py`):
   - Map CSV columns to database fields in the upload script
   - Add data cleaning/validation logic for your specific formats
   - Handle your specific data types and formats

3. **Search Endpoints**:
   - Replace `primary_value` with your main numeric field name
   - Update search ranges and filters appropriate for your data
   - Modify field names in SQL queries

4. **Frontend Labels**:
   - Update form labels and descriptions in templates
   - Change field names and terminology throughout
   - Modify analysis result displays for your domain

5. **Analysis Functions**:
   - Adapt temporal analysis to your time fields
   - Customize analysis logic for your data patterns
   - Create domain-specific analysis functions

### Template Replacements:
- `your_table_name` ‚Üí your actual table name
- `primary_value` ‚Üí your main numeric field
- `latitude/longitude` ‚Üí your location fields (if applicable)
- `time` ‚Üí your datetime field
- `description` ‚Üí your main text field
- Analysis themes ‚Üí your domain-specific patterns

## TESTING CHECKLIST

Before deployment, verify:
- [ ] Database connection works
- [ ] CSV upload processes successfully
- [ ] All search functions return correct results
- [ ] Error handling works properly
- [ ] Pagination functions correctly
- [ ] All analysis features work
- [ ] Mobile responsiveness
- [ ] Loading indicators display properly

## DEPLOYMENT

### Local Development:
```bash
python app.py
# Access at http://localhost:5000
```

### Production Deployment:
- Use Gunicorn: `gunicorn app:app`
- Configure environment variables properly
- Set up Azure App Service or similar platform
- Ensure database connectivity from production environment

## KEY IMPLEMENTATION NOTES

1. **Error Handling**: Every database operation should have try/catch blocks
2. **Data Validation**: Validate all user inputs before database queries
3. **SQL Injection Prevention**: Use parameterized queries
4. **Performance**: Index frequently searched fields
5. **User Experience**: Include loading indicators and progress bars
6. **Responsive Design**: Ensure mobile compatibility
7. **Pagination**: Implement for large datasets (10, 20, 50, 100 results per page)

This architecture provides a solid foundation for any data analysis web application. The patterns are proven, scalable, and professional-grade. Focus on adapting the database schema and field mappings to your specific dataset, and you'll have a powerful analysis platform ready quickly.